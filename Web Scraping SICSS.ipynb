{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9b2b1dc",
   "metadata": {},
   "source": [
    "# Web Scraping con Selenium en El Tiempo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11f1458",
   "metadata": {},
   "source": [
    "Este notebook muestra cómo automatizar la extracción de noticias desde el periódico El Tiempo utilizando Selenium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b21307",
   "metadata": {},
   "source": [
    "**¿Qué es Selenium?**   \n",
    "Selenium es una herramienta que nos permite automatizar navegadores web. Es como si escribiéramos un robot que abre una página, navega, hace clic y lee texto, igual que un humano."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8572d5f",
   "metadata": {},
   "source": [
    "**¿Cómo funciona el script?**\n",
    "1. Abre la página de búsqueda.\n",
    "2. Extrae todos los enlaces a noticias.\n",
    "3. Visita cada enlace y extrae la información requerida.\n",
    "4. Regresa a la página de búsqueda.\n",
    "5. Hace clic en “Siguiente” y repite el proceso hasta que no haya más noticias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13811db7",
   "metadata": {},
   "source": [
    "**¿Qué se almacena?**  \n",
    "Los datos extraídos se guardan en listas de Python, y finalmente se consolidan en un DataFrame que se exporta a Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ececccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instalar selenium\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e17b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias para el scraping con Selenium\n",
    "\n",
    "# webdriver: permite controlar el navegador (abrir páginas, hacer clics, etc.)\n",
    "from selenium import webdriver\n",
    "\n",
    "# By: se usa para seleccionar elementos HTML mediante su clase, ID, nombre de etiqueta, etc.\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Options: nos permite configurar opciones del navegador (como abrir en modo headless)\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# WebDriverWait: permite esperar de forma explícita a que ciertos elementos aparezcan en la página\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "# expected_conditions (EC): contiene condiciones que podemos esperar, como \"elemento visible\", \"elemento clickeable\", etc.\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# time: permite hacer pausas con time.sleep(), útil para evitar que la página se cargue demasiado rápido\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c8688f",
   "metadata": {},
   "source": [
    "**¿Qué es un WebDriver?**  \n",
    "Un WebDriver es el \"puente\" entre Python y el navegador (Chrome, Firefox, etc.).  \n",
    "Cuando usamos webdriver.Chrome(), estamos diciéndole a Python: \"Abre una ventana de Chrome y déjame controlarla\".\n",
    "\n",
    "El WebDriver:  \n",
    "· Abre el navegador  \n",
    "· Carga páginas web  \n",
    "· Encuentra elementos HTML (como botones, enlaces, textos)  \n",
    "· Interactúa con la página (clics, escritura, scroll, etc.)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ab639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos las opciones del navegador Chrome:\n",
    "options = webdriver.ChromeOptions()  # Creamos un objeto de configuración para personalizar cómo se abre el navegador.\n",
    "# NOTA: No activamos el modo \"headless\" para ver el navegador funcionando."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9fd63d",
   "metadata": {},
   "source": [
    "**¿Qué es un User-Agent?**  \n",
    "Un User-Agent es una cadena de texto que le dice al sitio web quién eres.\n",
    "\n",
    "Los servidores usan esto para:  \n",
    "· Mostrar una versión diferente de la página según el navegador  \n",
    "· Bloquear bots (como los que no tienen User-Agent o usan uno raro)  \n",
    "\n",
    "Con Selenium, podemos simular un navegador real agregando un User-Agent manualmente. Esto puede ayudar a evitar bloqueos y obtener el contenido completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e996f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquí estamos configurando un User-Agent personalizado.\n",
    "# Esto le dice al sitio web \"soy un navegador real, no un bot\".\n",
    "user_agent = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 13_3_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"\n",
    "# Usa este si trabajas en Windows: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b40d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadimos el User-Agent a las opciones del navegador:\n",
    "options.add_argument(f\"user-agent={user_agent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e49c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lanzamos el navegador con las opciones configuradas:\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97be91a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la URL semilla desde donde comenzará el scraping. \n",
    "# Puedes cambiar esta URL si deseas buscar otras palabras clave o categorías en El Tiempo.\n",
    "url_semilla = \"https://www.eltiempo.com/buscar/?q=fiebre%20amarilla&sort_search=desc&categories_ids_or=58&multiFields=&articleTypes=especial_modular%2Cespecial-tipo-d%2Cdefault%2Copinion%2Cobituario%2Ccarta%2Cpodcast%2Ceditorial%2Cforo%2Ccaricatura%2Cinfografia&from=&until=\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fe606b",
   "metadata": {},
   "source": [
    "**¿Por qué usar \"esperas\" (waits)?**  \n",
    "Cuando abrimos una página web, el contenido no siempre carga al instante, especialmente en sitios que usan JavaScript.\n",
    "\n",
    "Si intentamos buscar elementos demasiado pronto, obtendremos errores.\n",
    "\n",
    "Por eso usamos:  \n",
    "· WebDriverWait: para esperar de forma inteligente.  \n",
    "· expected_conditions: para decir \"espera hasta que aparezca cierto elemento\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfed2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le indicamos al navegador que abra la URL semilla, que contiene los resultados de búsqueda.\n",
    "driver.get(url_semilla)\n",
    "\n",
    "# Creamos un objeto de espera explícita que le dice a Selenium que espere hasta 10 segundos\n",
    "# para que los elementos necesarios aparezcan en la página antes de continuar.\n",
    "wait = WebDriverWait(driver, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba408bcf",
   "metadata": {},
   "source": [
    "**¿Qué son los selectores?**  \n",
    "Cuando queremos encontrar un elemento en una página, usamos selectores.  \n",
    "\n",
    "Estos se basan en atributos HTML como:  \n",
    "· By.ID: por el atributo id  \n",
    "· By.CLASS_NAME: por la clase CSS  \n",
    "· By.TAG_NAME: por el nombre de la etiqueta (como div, a, etc.)  \n",
    "· By.XPATH: usando expresiones XPath más avanzadas  \n",
    "· By.CSS_SELECTOR: usando selectores CSS como en estilos  \n",
    "\n",
    "**Ahora...**  \n",
    "Una vez ubicados los elementos, usamos al final de la ruta:  \n",
    "· click(): Esto simula el acto de hacer clic en el enlace identificado  \n",
    "· text(): Extrae la información en formato texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3542082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Localizamos el primer enlace de noticia usando su clase CSS y simulamos un clic para acceder a la noticia.\n",
    "driver.find_element(By.CLASS_NAME, \"c-article__title\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece3cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Localizamos el elemento que contiene el título completo de la noticia una vez que estamos dentro del artículo.\n",
    "titulo_noticia = driver.find_element(By.CLASS_NAME, \"c-articulo__titulo\").text\n",
    "# Mostramos el título en la consola\n",
    "print(titulo_noticia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae5eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora buscamos el subtítulo usando la clase CSS del contenedor de subtítulos.\n",
    "subtitulo_noticia = driver.find_element(By.CLASS_NAME, \"c-lead__titulo\").text\n",
    "print(subtitulo_noticia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3167d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos el cuerpo de la noticia, que también está identificado por una clase CSS.\n",
    "contenido_noticia = driver.find_element(By.CLASS_NAME, \"c-cuerpo\").text\n",
    "print(contenido_noticia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b88d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos la fecha de publicación de la noticia.\n",
    "# Usamos el nombre de la etiqueta <time>, ya que normalmente es único en la página y contiene la fecha.\n",
    "fecha_noticia = driver.find_element(By.TAG_NAME, \"time\").text\n",
    "print(fecha_noticia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3920aa3b",
   "metadata": {},
   "source": [
    "Logramos extraer la información de la primera noticia de nuestra búsqueda. Sin embargo, nuestro objetivo es automatizar todo el proceso para que el navegador recorra cada enlace de noticia en la página de resultados, acceda a cada uno, y extraiga el título, subtítulo, contenido y fecha. Al finalizar con todos los enlaces de la página actual, el navegador debe hacer clic en el botón \"Siguiente\" para continuar con la siguiente página de resultados y repetir el mismo procedimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a337de76",
   "metadata": {},
   "source": [
    "Para almacenar la información que extraeremos, crearemos listas vacías donde guardaremos los datos recolectados de cada noticia: el enlace (URL), el título, el subtítulo, el contenido y la fecha de publicación. Estas listas se llenarán automáticamente dentro de un bucle que recorrerá todas las noticias de cada página. A medida que el navegador visite cada noticia, iremos extrayendo los datos y agregándolos a las listas correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos listas vacías para almacenar la información extraída de cada noticia\n",
    "urls = []         # Aquí se guardarán los enlaces a cada noticia\n",
    "titulos = []      # Aquí se almacenarán los títulos de las noticias\n",
    "subtitulos = []   # Aquí se almacenarán los subtítulos (si existen)\n",
    "contenidos = []   # Aquí se guardará el cuerpo completo del texto de cada noticia\n",
    "fechas = []       # Aquí se guardarán las fechas de publicación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eea7f11",
   "metadata": {},
   "source": [
    "**¡Recordatorio!**  \n",
    "Una lista en Python es una estructura que permite almacenar múltiples elementos en un solo objeto. Se define con corchetes [] y puede crecer dinámicamente. En este caso, usaremos listas para ir guardando la información de cada noticia que vayamos extrayendo durante el proceso de scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab5a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos un bucle que continuará hasta que ya no haya más páginas\n",
    "while True:\n",
    "    # Esperamos que se carguen todos los enlaces a noticias en la página\n",
    "    wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//h3/a[@href]\")))\n",
    "    # Obtenemos todos los elementos <a> que representan los enlaces a las noticias\n",
    "    article_links = driver.find_elements(By.XPATH, \"//h3/a[@href]\")\n",
    "    \n",
    "    # Creamos una lista con los href únicos extraídos de cada enlace\n",
    "    current_page_urls = [link.get_attribute(\"href\") for link in article_links if link.get_attribute(\"href\")]\n",
    "    \n",
    "    # Recorremos cada URL de noticia encontrada en la página actual\n",
    "    for url in current_page_urls:\n",
    "        try:\n",
    "            # Abrimos la URL de la noticia en una nueva pestaña del navegador\n",
    "            driver.execute_script(\"window.open(arguments[0]);\", url)\n",
    "            # Cambiamos el control a la nueva pestaña abierta\n",
    "            driver.switch_to.window(driver.window_handles[1])\n",
    "            # Esperamos que se cargue el título de la noticia\n",
    "            wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"c-articulo__titulo\")))\n",
    "            \n",
    "            # Extraemos el título de la noticia\n",
    "            title = driver.find_element(By.CLASS_NAME, \"c-articulo__titulo\").text\n",
    "            try:\n",
    "                # Extraemos el subtítulo de la noticia si existe\n",
    "                subtitle = driver.find_element(By.CLASS_NAME, \"c-lead__titulo\").text\n",
    "            except:\n",
    "                subtitle = \"\"\n",
    "            try:\n",
    "                # Extraemos todos los párrafos del cuerpo de la noticia\n",
    "                body_paragraphs = driver.find_elements(By.CLASS_NAME, \"c-cuerpo\")\n",
    "                # Unimos los párrafos extraídos en un solo texto de contenido\n",
    "                content = \"\\n\".join(p.text for p in body_paragraphs)\n",
    "            except:\n",
    "                content = \"\"\n",
    "            try:\n",
    "                # Extraemos la fecha de publicación de la noticia\n",
    "                date = driver.find_element(By.TAG_NAME, \"time\").text\n",
    "            except:\n",
    "                date = \"\"\n",
    "            \n",
    "            # Guardamos la URL y los datos extraídos en sus respectivas listas\n",
    "            urls.append(url)\n",
    "            titulos.append(title)\n",
    "            subtitulos.append(subtitle)\n",
    "            contenidos.append(content)\n",
    "            fechas.append(date)\n",
    "\n",
    "        # Si ocurre un error al procesar la noticia, lo mostramos por consola\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {url}: {e}\")\n",
    "        finally:\n",
    "            # Cerramos la pestaña actual de la noticia\n",
    "            driver.close()\n",
    "            # Volvemos a la pestaña de resultados de búsqueda\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "    # Pasamos a la siguiente página\n",
    "    try:\n",
    "        # Buscamos el botón de 'Siguiente' para avanzar de página\n",
    "        next_button = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, \"next\")))\n",
    "        # Hacemos clic en el botón de 'Siguiente'\n",
    "        next_button.click()\n",
    "        # Esperamos un momento para asegurar que la página siguiente cargue correctamente\n",
    "        time.sleep(2)\n",
    "    except:\n",
    "        print(\"No hay más páginas.\")\n",
    "        # Si no hay más botón de 'Siguiente', terminamos el bucle\n",
    "        break\n",
    "\n",
    "# Cerramos completamente el navegador al terminar\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2a213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos la lista completa de URLs extraídas\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f16117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos la lista completa de títulos extraídos\n",
    "print(titulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412b2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos la lista completa de subtítulos extraídos\n",
    "print(subtitulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615167c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos la lista completa de contenidos extraídos\n",
    "print(contenidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd181948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostramos la lista completa de fechas extraídas\n",
    "print(fechas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa2f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime la cantidad de elementos extraídos en cada lista.\n",
    "# Esto nos ayuda a verificar que todas las listas tengan la misma longitud.\n",
    "print(len(urls))         # Número de URLs extraídas\n",
    "print(len(titulos))      # Número de títulos extraídos\n",
    "print(len(subtitulos))   # Número de subtítulos extraídos\n",
    "print(len(contenidos))   # Número de contenidos extraídos\n",
    "print(len(fechas))       # Número de fechas extraídas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4e9340",
   "metadata": {},
   "source": [
    "**¡Nota!**  \n",
    "Para poder crear un DataFrame, es importante que todas las listas tengan la misma longitud. Cada fila del DataFrame representa una noticia, por lo que si alguna lista tiene más o menos elementos, pandas no podrá alinear los datos correctamente y generará un error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instalar pandas (en caso de que no la tengamos)\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f04e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la biblioteca pandas, que nos permite manipular datos en forma de tablas (DataFrames).\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78865e8d",
   "metadata": {},
   "source": [
    "**¡Recordatorio!**  \n",
    "Un diccionario en Python es una estructura de datos que almacena pares de clave y valor. Las claves (por ejemplo, \"Título\", \"Fecha\") actúan como etiquetas, y cada una apunta a un valor (en este caso, una lista de datos extraídos). Se define usando llaves {}. En nuestro caso, usaremos un diccionario para agrupar todas las listas de noticias extraídas y luego convertirlo en un DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3644459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un diccionario donde agrupamos toda la información extraída por campos: URL, título, subtítulo, contenido y fecha.\n",
    "noticias_eltiempo_migracion = {\n",
    "    'URL': urls,\n",
    "    'Título': titulos,\n",
    "    'Subtítulo': subtitulos,\n",
    "    'Contenido': contenidos,\n",
    "    'Fecha': fechas\n",
    "}\n",
    "\n",
    "# Convertimos el diccionario en un DataFrame de pandas, que es como una hoja de cálculo en memoria.\n",
    "df = pd.DataFrame(noticias_eltiempo_migracion)\n",
    "df # Mostramos el DataFrame como salida en Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b32aa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportamos el DataFrame a un archivo Excel. Usamos index=False para no guardar los índices de las filas.\n",
    "df.to_excel('noticias_eltiempo_fiebreamarilla.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
